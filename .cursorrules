# Cursor rules for openai-structured project

# Ignore directories
ignore:
  - .git
  - .venv
  - __pycache__
  - .pytest_cache
  - build
  - dist
  - *.egg-info

# File type associations
associations:
  - pattern: "*.py"
    language: python
  - pattern: "*.md"
    language: markdown
  - pattern: "*.json"
    language: json
  - pattern: "*.yaml"
    language: yaml
  - pattern: "*.yml"
    language: yaml

# Editor settings
settings:
  python:
    tabSize: 4
    insertSpaces: true
    trimTrailingWhitespace: true
    insertFinalNewline: true 

# OpenAI models
The only models that support the 
- gpt-4o-2024-08-06 and later: 128K context window, 16K max output tokens
- gpt-4o-mini-2024-07-18 and later: 128K context window, 16K max output tokens
- o1-2024-12-17 and later: 200K context window, 100K max output tokens

Note that:
 - gpt-4o is alias for the latest version of gpt-4o.
 - gpt-4o-mini is alias for the latest version of gpt-4o-mini.
 - o1 is alias for the latest version of o1.

 When creating tests or samples, unless instructed otherwise, use "gpt-4o" as the model.

# Fixing code
Before you attempt to fix code, make sure you have a good understanding of the codebase:
- Always perform a thorough review of the codebase before attempting to fix code.
- Perform root cause analysis to understand the issue and the code that needs to be fixed.
- If you are not sure about the best way to fix the code, ask the user for clarification.

# Key learnings

1. **Mock Implementation Details Matter**
   - The way we implement `__iter__` in mocks is crucial - using `return_value=iter(chunks)` wasn't sufficient
   - Using a proper generator function with `side_effect` provided better control and debugging visibility
   - Each mock chunk needs to fully simulate the OpenAI response structure (choices, delta, content)

2. **Logging is Essential for Streaming Issues**
   - Adding detailed logging at each step helped identify where the stream processing was failing
   - Key points to log include:
     - Chunk creation and structure
     - Stream iteration start/end
     - Content processing attempts
     - Buffer operations

3. **Test Design Patterns**
   - Mock responses should be protocol-compliant, matching the exact structure of real OpenAI responses
   - For streaming tests, we need to verify both the iteration mechanism and the content processing
   - Having separate sync and async test cases helps catch implementation-specific issues

4. **Debugging Strategy**
   - Start with adding comprehensive logging before making changes
   - Verify each component (mock creation, iteration, processing) independently
   - Make small, focused changes and validate with tests
   - When dealing with streaming issues, trace the full lifecycle of each chunk

5. **Common Pitfalls to Watch For**
   - Mock objects need all required attributes and methods
   - Streaming implementations need proper iteration protocol support
   - Buffer management and cleanup need to be handled in both success and error cases
   - Async and sync implementations have different requirements for iteration

